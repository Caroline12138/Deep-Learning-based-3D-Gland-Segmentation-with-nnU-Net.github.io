<!doctype html>
<html lang="en">

<head>
    <style>
        .p1{
            margin-top: 80px;
            text-align: center;
            font-size: 35px;
        }
        .button1 {
            background-color: white;
            color: black;
            border: 2px white;
            padding: 15px 32px;
            font-size: 20px;
            border-radius: 8px;
            float: left;
          }
        .ab{

            font-size: 25px;
            text-align: center;
            margin-top: 35px;
        }
        .button1:hover {background-color: #e7e7e7;}
        img {
            display: block;
            margin-left: auto;
            margin-right: auto;
            margin-top: 80px;
            width: 50%;
        }
        a:hover {
            color: rgb(12, 96, 145);
            background-color: transparent;
            text-decoration: none;
          }
    </style>
</head>

<body>
    <a href="cse455.html" class="button button1">Home</a>
    <a href="introduction.html" class="button button1">Introduction</a>
    <a href="dataset.html"   class="button button1">Data</a>
    <a href="method.html"  class="button button1">Methdology</a>
    <a href="experiment.html"  class="button button1">Experiment & Results</a>
    <a href="Conclusion.html"  class="button button1">Conclusion</a>
    <br>
    <p class = "p1">Deep Learning-based 3D Gland Segmentation with nnU-Net</p>
    <img src="../Figure/figure1.jpg">
    <br>
    <div class = "ab">
        <p>
            Author : Rui Wang, Xinran Wang
        </p>
        <p>
            This is the final project for 
            <a href="https://courses.cs.washington.edu/courses/cse455/23wi/">CSE 455 Computer Vision</a>
            , University of Washington
        </p>
    </div>
    <!-- <div id = "ab" class = "ab"> 

        <center><h2>Abstract</h2></center>

        <p>Semantic segmentation is useful to segment out different parts in tissues 
            from microscopic biomedical images. However, it is a tough task to do traditional 
            computer vision-based segmentation in 3D since both the continuity and context information need 
            to be considered for all three directions, many parameters need to be taken into account and much 
            manual examination and tweaking make it tedious and time-consuming. Deep learning-based semantic 
            segmentation remains as a promising technology to deal with such problem since the models generate 
            well on different datasets with similar properties. Once well trained, no more manual efforts need 
            to be done. There are already a lot of successful deep learning models for specific segmentation
            tasks of 3D biomedical images. nnU-Net is a self-configuring model for various biomedical 
            segmentation tasks. It can configure different network structures, pre/post-processing pipelines, 
            etc based on the dataset properties like imaging modality, image sizes, voxel spacings, class 
            ratios, etc. In this project, we adapt nnU-Net to train a model which is capable of segmenting 
            out epithelium and lumen of synthetic immunolabeled prostate glands in 3D images.</p>
      </div> -->
      <!-- <div id = "in" class = "in"> 
        <center><h2>Introduction</h2></center>
        <p>Semantic segmentation is useful to segment out different parts in tissues 
            from microscopic biomedical images. However, it is a tough task to do traditional 
            computer vision-based segmentation in 3D since both the continuity and context information need 
            to be considered for all three directions, many parameters need to be taken into account and much 
            manual examination and tweaking make it tedious and time-consuming. Deep learning-based semantic 
            segmentation remains as a promising technology to deal with such problem since the models generate 
            well on different datasets with similar properties. Once well trained, no more manual efforts need 
            to be done. There are already a lot of successful deep learning models for specific segmentation
            tasks of 3D biomedical images. nnU-Net is a self-configuring model for various biomedical 
            segmentation tasks. It can configure different network structures, pre/post-processing pipelines, 
            etc based on the dataset properties like imaging modality, image sizes, voxel spacings, class 
            ratios, etc. In this project, we adapt nnU-Net to train a model which is capable of segmenting 
            out epithelium and lumen of synthetic immunolabeled prostate glands in 3D images.</p>
      </div>
      <div id = "da" class = "da"> 
        <center><h2>Dataset</h2></center>
        <p>Semantic segmentation is useful to segment out different parts in tissues 
            from microscopic biomedical images. However, it is a tough task to do traditional 
            computer vision-based segmentation in 3D since both the continuity and context information need 
            to be considered for all three directions, many parameters need to be taken into account and much 
            manual examination and tweaking make it tedious and time-consuming. Deep learning-based semantic 
            segmentation remains as a promising technology to deal with such problem since the models generate 
            well on different datasets with similar properties. Once well trained, no more manual efforts need 
            to be done. There are already a lot of successful deep learning models for specific segmentation
            tasks of 3D biomedical images. nnU-Net is a self-configuring model for various biomedical 
            segmentation tasks. It can configure different network structures, pre/post-processing pipelines, 
            etc based on the dataset properties like imaging modality, image sizes, voxel spacings, class 
            ratios, etc. In this project, we adapt nnU-Net to train a model which is capable of segmenting 
            out epithelium and lumen of synthetic immunolabeled prostate glands in 3D images.</p>
      </div> -->
</body>
</html>